#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–±–æ—Ä–∞ –≤—Å–µ—Ö —Å—Å—ã–ª–æ–∫ –∏–∑ –Ω–∞—á–∞–ª—å–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã.
–ü—Ä–æ—Å—Ç–æ —É–∫–∞–∂–∏—Ç–µ –Ω–∞—á–∞–ª—å–Ω—É—é —Å—Å—ã–ª–∫—É, –∏ —Å–∫—Ä–∏–ø—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞–π–¥–µ—Ç –∏ –¥–æ–±–∞–≤–∏—Ç –≤—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö.
"""
import requests
import json
import sys
import time

API_URL = "http://127.0.0.1:8000/api/crawl/start"
STATUS_URL = "http://127.0.0.1:8000/api/crawl/status"

def start_recursive_crawl(start_url):
    """–ó–∞–ø—É—Å—Ç–∏—Ç—å —Ä–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π –∫—Ä–∞—É–ª–∏–Ω–≥ —Å —É–∫–∞–∑–∞–Ω–Ω–æ–π –Ω–∞—á–∞–ª—å–Ω–æ–π —Å—Å—ã–ª–∫–∏."""
    try:
        print(f"üöÄ –ó–∞–ø—É—Å–∫ —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ–≥–æ –∫—Ä–∞—É–ª–∏–Ω–≥–∞ —Å: {start_url}")
        print("‚è≥ –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –≤—Ä–µ–º—è...\n")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –∫—Ä–∞—É–ª–∏–Ω–≥
        response = requests.post(
            API_URL,
            json={"start_url": start_url},
            timeout=10
        )
        
        if response.status_code == 200:
            result = response.json()
            print(f"‚úì –ö—Ä–∞—É–ª–∏–Ω–≥ –∑–∞–ø—É—â–µ–Ω!")
            print(f"–ù–∞—á–∞–ª—å–Ω–∞—è —Å—Å—ã–ª–∫–∞: {result.get('start_url', start_url)}")
            print(f"\n–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ.")
            print("–ú–æ–∂–µ—Ç–µ –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å —á–µ—Ä–µ–∑ —Å—Ç–∞—Ç—É—Å.\n")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç—É—Å –∫–∞–∂–¥—ã–µ 5 —Å–µ–∫—É–Ω–¥
            print("=" * 60)
            print("–°—Ç–∞—Ç—É—Å –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è –∫–∞–∂–¥—ã–µ 5 —Å–µ–∫—É–Ω–¥):")
            print("=" * 60)
            
            while True:
                try:
                    status_response = requests.get(STATUS_URL, timeout=5)
                    if status_response.status_code == 200:
                        status = status_response.json()
                        
                        is_crawling = status.get('is_crawling', False)
                        visited = status.get('visited_count', 0)
                        queue = status.get('queue_size', 0)
                        stats = status.get('stats', {})
                        total_crawled = stats.get('total_crawled', 0)
                        total_failed = stats.get('total_failed', 0)
                        
                        print(f"\rüìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {visited} | –í –æ—á–µ—Ä–µ–¥–∏: {queue} | –£—Å–ø–µ—à–Ω–æ: {total_crawled} | –û—à–∏–±–æ–∫: {total_failed}", end="")
                        
                        if not is_crawling and queue == 0:
                            print("\n\n‚úì –ö—Ä–∞—É–ª–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω!")
                            print(f"–í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å—Ç—Ä–∞–Ω–∏—Ü: {visited}")
                            print(f"–£—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {total_crawled}")
                            if total_failed > 0:
                                print(f"–û—à–∏–±–æ–∫: {total_failed}")
                            break
                    
                    time.sleep(5)
                    
                except KeyboardInterrupt:
                    print("\n\n‚ö† –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
                    print("–ö—Ä–∞—É–ª–∏–Ω–≥ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç—Å—è –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ.")
                    print("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å—Ç–∞—Ç—É—Å: http://127.0.0.1:8000/api/crawl/status")
                    break
                except Exception as e:
                    print(f"\n‚ö† –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Å—Ç–∞—Ç—É—Å–∞: {e}")
                    time.sleep(5)
            
            return True
        else:
            print(f"‚úó –û—à–∏–±–∫–∞: {response.status_code}")
            print(f"–û—Ç–≤–µ—Ç: {response.text}")
            return False
            
    except requests.exceptions.ConnectionError:
        print("‚úó –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ —Å–µ—Ä–≤–µ—Ä—É.")
        print("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω: uvicorn app.main:app --reload")
        return False
    except Exception as e:
        print(f"‚úó –û—à–∏–±–∫–∞: {e}")
        return False


if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:")
        print("  python crawl_recursive.py <–Ω–∞—á–∞–ª—å–Ω–∞—è_—Å—Å—ã–ª–∫–∞>")
        print("\n–ü—Ä–∏–º–µ—Ä:")
        print("  python crawl_recursive.py https://elma365.com/ru/help")
        print("\n–°–∫—Ä–∏–ø—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞–π–¥–µ—Ç –∏ –¥–æ–±–∞–≤–∏—Ç –í–°–ï —Å—Å—ã–ª–∫–∏,")
        print("–Ω–∞—á–∏–Ω–∞—è —Å —É–∫–∞–∑–∞–Ω–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã, –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö.")
        sys.exit(1)
    
    start_url = sys.argv[1]
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –≤–∞–ª–∏–¥–Ω–∞—è —Å—Å—ã–ª–∫–∞
    if not start_url.startswith('http'):
        print("‚úó –û—à–∏–±–∫–∞: –£–∫–∞–∂–∏—Ç–µ –ø–æ–ª–Ω—É—é —Å—Å—ã–ª–∫—É (–Ω–∞—á–∏–Ω–∞—é—â—É—é—Å—è —Å http:// –∏–ª–∏ https://)")
        sys.exit(1)
    
    print("=" * 60)
    print("–†–ï–ö–£–†–°–ò–í–ù–´–ô –ö–†–ê–£–õ–ò–ù–ì")
    print("=" * 60)
    print()
    
    success = start_recursive_crawl(start_url)
    
    if success:
        print("\n" + "=" * 60)
        print("–ì–æ—Ç–æ–≤–æ! –í—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö.")
        print("–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã: http://127.0.0.1:8000/api/docs")
        print("=" * 60)
    else:
        sys.exit(1)

